# -*- coding: utf-8 -*-
"""Heart disease classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFT_Kpg7PDv48jAA4vytS2189NNEc46n
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/Heart Attack.csv')

df.head()

df.info()

df.describe()

df.isnull().sum()

sns.heatmap(df.corr())

df.hist(bins=20, figsize =(15,10), color= 'maroon')

df.dtypes

cols = df.columns
for col in cols:
  print(col)

  print(df[col].unique())
  print('------------------')

df['class'] = df['class'].replace({'negative': 0})
df['class'] = df['class'].replace({'positive': 1})

df.dtypes

cr=df.corr()
cr_df= cr['class'].sort_values(ascending= False)
cr_df

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import explained_variance_score,mean_absolute_error,r2_score
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

X = df.drop('class', axis=1)
y = df['class']


# Split the dataset into train and test sets
x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)

param_grid_rf = {
    'classifier__n_estimators': [50, 150, 250],
    'classifier__max_depth': [3, 5, 10],
    'classifier__min_samples_split': [2, 5, 10],
    'classifier__min_samples_leaf': [1, 2, 4],
}

pipeline_rf = Pipeline([
    ('classifier', RandomForestClassifier(random_state=42))
])

grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_rf.fit(x_train, y_train)

best_model_rf, best_score_rf = grid_search_rf.best_estimator_, grid_search_rf.best_score_

y_pred_rf = best_model_rf.predict(x_test)

accuracy_rf = accuracy_score(y_test, y_pred_rf)

accuracy_rf

importances_rf = best_model_rf.named_steps['classifier'].feature_importances_

importances_rf

param_grid_gb = {
    'classifier__n_estimators': [50, 150, 250],
    'classifier__learning_rate': [0.01, 0.1, 1],
    'classifier__max_depth': [3, 5, 10],
}

pipeline_gb = Pipeline([
    ('classifier', GradientBoostingClassifier(random_state=42))
])

grid_search_gb = GridSearchCV(pipeline_gb, param_grid_gb, cv=5, scoring='accuracy', n_jobs=-1)
grid_search_gb.fit(x_train, y_train)

best_model_gb, best_score_gb = grid_search_gb.best_estimator_, grid_search_gb.best_score_

y_pred_gb = best_model_gb.predict(x_test)

accuracy_gb = accuracy_score(y_test, y_pred_gb)

accuracy_gb

importances_gb = best_model_rf.named_steps['classifier'].feature_importances_

importances_gb

lr= LogisticRegression(max_iter=1000)
lr.fit(x_train, y_train)

y_pred_lr= lr.predict(x_test)

accuracy_lr = accuracy_score(y_test, y_pred_lr)

accuracy_lr

knn= KNeighborsClassifier()
knn.fit(x_train, y_train)

y_pred_knn= knn.predict(x_test)

accuracy_knn = accuracy_score(y_test, y_pred_knn)

accuracy_knn

dtc= DecisionTreeClassifier()
dtc.fit(x_train, y_train)

y_pred_dtc= dtc.predict(x_test)

accuracy_dtc = accuracy_score(y_test, y_pred_dtc)

accuracy_dtc

